"""
Syst√®me de Recherche ChromaDB pour LegalDocBot
Utilise la base ChromaDB avec 12,024 chunks pour enrichir l'analyse
"""

import chromadb
from typing import List, Dict, Optional
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ChromaDBSearch:
    """
    Syst√®me de recherche ChromaDB pour la base de connaissances juridique
    """
    
    def __init__(self):
        """Initialise la connexion √† ChromaDB"""
        try:
            self.client = chromadb.PersistentClient(path='chroma_db')
            
            # V√©rifier si les collections existent
            available_collections = [c.name for c in self.client.list_collections()]
            logger.info(f"üìö Collections disponibles: {available_collections}")
            
            # Essayer de charger les collections attendues
            self.collections = {}
            expected_collections = {
                'deontologie': 'deontologie',
                'csp': 'csp_legislation',
                'css': 'css_legislation', 
                'penal': 'penal_legislation',
                'civil': 'civil_legislation'
            }
            
            for key, collection_name in expected_collections.items():
                if collection_name in available_collections:
                    try:
                        self.collections[key] = self.client.get_collection(collection_name)
                        logger.info(f"‚úÖ Collection {collection_name} charg√©e")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erreur chargement {collection_name}: {e}")
                else:
                    logger.warning(f"‚ö†Ô∏è Collection {collection_name} manquante")
            
            if self.collections:
                logger.info("‚úÖ ChromaDB connect√© avec succ√®s")
                self.is_available = True
            else:
                logger.warning("‚ö†Ô∏è Aucune collection ChromaDB disponible")
                self.is_available = False
                
        except Exception as e:
            logger.error(f"‚ùå Erreur connexion ChromaDB: {e}")
            self.is_available = False
    
    def search_legal_knowledge(self, query: str, top_k: int = 10, use_reranking: bool = True) -> List[Dict]:
        """
        Recherche dans toute la base de connaissances ChromaDB avec reranking optionnel
        
        Args:
            query: Requ√™te de recherche
            top_k: Nombre maximum de r√©sultats par collection
            use_reranking: Utiliser le cross-encoder pour reranker les r√©sultats
            
        Returns:
            Liste des chunks pertinents avec m√©tadonn√©es
        """
        if not self.is_available:
            logger.warning("‚ö†Ô∏è ChromaDB non disponible")
            return []
        
        all_results = []
        
        try:
            # Recherche dans toutes les collections
            for collection_name, collection in self.collections.items():
                try:
                    results = collection.query(
                        query_texts=[query],
                        n_results=top_k,
                        include=['metadatas', 'documents', 'distances']
                    )
                    
                    if results['documents'] and results['documents'][0]:
                        for i, (doc, metadata, distance) in enumerate(zip(
                            results['documents'][0],
                            results['metadatas'][0],
                            results['distances'][0]
                        )):
                            # Calculer un score de pertinence (distance inverse)
                            relevance_score = max(0, 1 - distance)
                            
                            result = {
                                'content': doc,
                                'metadata': metadata,
                                'collection': collection_name,
                                'relevance_score': relevance_score,
                                'source': metadata.get('source_file', 'Inconnu'),
                                'article': metadata.get('article', ''),
                                'doc_type': metadata.get('doc_type', '')
                            }
                            all_results.append(result)
                            
                except Exception as e:
                    logger.error(f"‚ùå Erreur recherche {collection_name}: {e}")
            
            # Reranking avec cross-encoder si demand√©
            if use_reranking and all_results:
                try:
                    from chromadb_reranker import get_chromadb_reranker
                    reranker = get_chromadb_reranker()
                    if reranker.is_available:
                        logger.info("üîç Application du reranking cross-encoder...")
                        all_results = reranker.rerank_chromadb_results(all_results, query)
                    else:
                        # Trier par score de pertinence si pas de reranking
                        all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
                except Exception as e:
                    logger.error(f"‚ùå Erreur reranking: {e}")
                    # Trier par score de pertinence en cas d'erreur
                    all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            else:
                # Trier par score de pertinence
                all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            logger.info(f"‚úÖ Recherche ChromaDB: {len(all_results)} r√©sultats trouv√©s")
            return all_results[:top_k * 2]  # Retourner plus de r√©sultats pour diversit√©
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche ChromaDB: {e}")
            return []
    
    def search_deontologie(self, query: str, top_k: int = 5, use_reranking: bool = True) -> List[Dict]:
        """
        Recherche sp√©cifique dans la collection d√©ontologie avec reranking optionnel
        
        Args:
            query: Requ√™te de recherche
            top_k: Nombre maximum de r√©sultats
            use_reranking: Utiliser le cross-encoder pour reranker les r√©sultats
            
        Returns:
            Liste des chunks de d√©ontologie pertinents
        """
        if not self.is_available or 'deontologie' not in self.collections:
            return []
        
        try:
            results = self.collections['deontologie'].query(
                query_texts=[query],
                n_results=top_k,
                include=['metadatas', 'documents', 'distances']
            )
            
            deont_results = []
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0],
                    results['metadatas'][0],
                    results['distances'][0]
                )):
                    relevance_score = max(0, 1 - distance)
                    
                    result = {
                        'content': doc,
                        'metadata': metadata,
                        'collection': 'deontologie',
                        'relevance_score': relevance_score,
                        'source': metadata.get('source_file', 'codedeont.pdf'),
                        'article': metadata.get('article', ''),
                        'doc_type': 'deontologie'
                    }
                    deont_results.append(result)
            
            # Reranking avec cross-encoder si demand√©
            if use_reranking and deont_results:
                try:
                    from chromadb_reranker import get_chromadb_reranker
                    reranker = get_chromadb_reranker()
                    if reranker.is_available:
                        logger.info("üîç Application du reranking cross-encoder d√©ontologie...")
                        deont_results = reranker.rerank_deontologie_results(deont_results, query)
                    else:
                        # Trier par score de pertinence si pas de reranking
                        deont_results.sort(key=lambda x: x['relevance_score'], reverse=True)
                except Exception as e:
                    logger.error(f"‚ùå Erreur reranking d√©ontologie: {e}")
                    # Trier par score de pertinence en cas d'erreur
                    deont_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            else:
                # Trier par score de pertinence
                deont_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            logger.info(f"‚úÖ Recherche d√©ontologie: {len(deont_results)} r√©sultats")
            return deont_results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche d√©ontologie: {e}")
            return []
    
    def search_csp(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        Recherche sp√©cifique dans le Code de la sant√© publique
        
        Args:
            query: Requ√™te de recherche
            top_k: Nombre maximum de r√©sultats
            
        Returns:
            Liste des chunks CSP pertinents
        """
        if not self.is_available or 'csp' not in self.collections:
            return []
        
        try:
            results = self.collections['csp'].query(
                query_texts=[query],
                n_results=top_k,
                include=['metadatas', 'documents', 'distances']
            )
            
            csp_results = []
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0],
                    results['metadatas'][0],
                    results['distances'][0]
                )):
                    relevance_score = max(0, 1 - distance)
                    
                    result = {
                        'content': doc,
                        'metadata': metadata,
                        'collection': 'csp',
                        'relevance_score': relevance_score,
                        'source': metadata.get('source_file', 'Code de la sant√© publique.pdf'),
                        'article': metadata.get('article', ''),
                        'doc_type': 'csp'
                    }
                    csp_results.append(result)
            
            logger.info(f"‚úÖ Recherche CSP: {len(csp_results)} r√©sultats")
            return csp_results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche CSP: {e}")
            return []
    
    def search_unified_legal_knowledge(self, query: str, top_k: int = 15, use_reranking: bool = True) -> List[Dict]:
        """
        Recherche UNIFI√âE dans TOUTE la base de connaissances ChromaDB
        Retourne les MEILLEURS articles de TOUTES les sources (CSP, d√©ontologie, CSS, civil, p√©nal)
        
        Args:
            query: Requ√™te de recherche
            top_k: Nombre maximum de r√©sultats totaux
            use_reranking: Utiliser le cross-encoder pour reranker les r√©sultats
            
        Returns:
            Liste des MEILLEURS chunks de TOUTES les sources juridiques
        """
        if not self.is_available:
            logger.warning("‚ö†Ô∏è ChromaDB non disponible")
            return []
        
        all_results = []
        
        try:
            # Recherche dans TOUTES les collections en parall√®le
            for collection_name, collection in self.collections.items():
                try:
                    # Recherche plus large dans chaque collection
                    results = collection.query(
                        query_texts=[query],
                        n_results=top_k,  # Plus de r√©sultats par collection
                        include=['metadatas', 'documents', 'distances']
                    )
                    
                    if results['documents'] and results['documents'][0]:
                        for i, (doc, metadata, distance) in enumerate(zip(
                            results['documents'][0],
                            results['metadatas'][0],
                            results['distances'][0]
                        )):
                            # Calculer un score de pertinence (distance inverse)
                            relevance_score = max(0, 1 - distance)
                            
                            result = {
                                'content': doc,
                                'metadata': metadata,
                                'collection': collection_name,
                                'relevance_score': relevance_score,
                                'source': metadata.get('source_file', 'Inconnu'),
                                'article': metadata.get('article', ''),
                                'doc_type': metadata.get('doc_type', ''),
                                'source_type': self._get_source_type(collection_name)
                            }
                            all_results.append(result)
                            
                except Exception as e:
                    logger.error(f"‚ùå Erreur recherche {collection_name}: {e}")
            
            logger.info(f"üîç Recherche unifi√©e: {len(all_results)} r√©sultats trouv√©s dans toutes les sources")
            
            # Reranking UNIFI√â avec cross-encoder pour TOUS les r√©sultats
            if use_reranking and all_results:
                try:
                    from chromadb_reranker import get_chromadb_reranker
                    reranker = get_chromadb_reranker()
                    if reranker.is_available:
                        logger.info("üîç Application du reranking cross-encoder UNIFI√â...")
                        all_results = reranker.rerank_unified_results(all_results, query)
                    else:
                        # Trier par score de pertinence si pas de reranking
                        all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
                except Exception as e:
                    logger.error(f"‚ùå Erreur reranking unifi√©: {e}")
                    # Trier par score de pertinence en cas d'erreur
                    all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            else:
                # Trier par score de pertinence
                all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            logger.info(f"‚úÖ Recherche unifi√©e termin√©e: {len(all_results[:top_k])} meilleurs r√©sultats de toutes les sources")
            return all_results[:top_k]  # Retourner les meilleurs de toutes les sources
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche unifi√©e ChromaDB: {e}")
            return []
    
    def _get_source_type(self, collection_name: str) -> str:
        """
        Retourne le type de source pour l'affichage
        
        Args:
            collection_name: Nom de la collection
            
        Returns:
            Type de source lisible
        """
        source_types = {
            'deontologie': 'Code de D√©ontologie M√©dicale',
            'csp': 'Code de la Sant√© Publique',
            'css': 'Code de la S√©curit√© Sociale',
            'penal': 'Code P√©nal',
            'civil': 'Code Civil'
        }
        return source_types.get(collection_name, collection_name.upper())
    
    def get_collection_stats(self) -> Dict:
        """
        Retourne les statistiques des collections
        
        Returns:
            Dictionnaire avec les statistiques
        """
        if not self.is_available:
            return {}
        
        stats = {}
        for collection_name, collection in self.collections.items():
            try:
                count = collection.count()
                stats[collection_name] = count
            except Exception as e:
                logger.error(f"‚ùå Erreur stats {collection_name}: {e}")
                stats[collection_name] = 0
        
        return stats

# Instance globale
chromadb_search = None

def get_chromadb_search() -> ChromaDBSearch:
    """Retourne l'instance du syst√®me de recherche ChromaDB (singleton)"""
    global chromadb_search
    if chromadb_search is None:
        chromadb_search = ChromaDBSearch()
    return chromadb_search

def test_chromadb_search():
    """Test du syst√®me de recherche ChromaDB"""
    
    print("üß™ TEST CHROMADB SEARCH")
    print("=" * 40)
    
    # Test d'initialisation
    search = get_chromadb_search()
    
    if not search.is_available:
        print("‚ùå ChromaDB non disponible")
        return
    
    # Statistiques
    stats = search.get_collection_stats()
    print("üìä Statistiques des collections:")
    for collection, count in stats.items():
        print(f"  - {collection}: {count} chunks")
    
    # Test de recherche UNIFI√âE
    test_query = "secret m√©dical et responsabilit√© m√©dicale"
    print(f"\nüîç Test RECHERCHE UNIFI√âE: '{test_query}'")
    
    # Recherche unifi√©e
    unified_results = search.search_unified_legal_knowledge(test_query, top_k=10)
    print(f"‚úÖ Recherche unifi√©e: {len(unified_results)} r√©sultats de toutes les sources")
    
    # Grouper par source
    sources = {}
    for result in unified_results:
        source_type = result.get('source_type', result['collection'].upper())
        if source_type not in sources:
            sources[source_type] = []
        sources[source_type].append(result)
    
    # Afficher les r√©sultats par source
    for source_type, results in sources.items():
        print(f"\nüìö {source_type}:")
        for i, result in enumerate(results[:3], 1):
            final_score = result.get('final_score', result['relevance_score'])
            print(f"  {i}. Article {result['article']} (Score: {final_score:.2f})")
            if result.get('reranked'):
                cross_score = result.get('cross_encoder_score', 0)
                source_bonus = result.get('source_bonus', 0)
                print(f"     Cross-Encoder: {cross_score:.2f} | Bonus: {source_bonus:.2f}")
    
    # Test de recherche classique
    test_queries = [
        "secret m√©dical",
        "consentement √©clair√©",
        "responsabilit√© m√©dicale",
        "obligation d'information"
    ]
    
    for query in test_queries:
        print(f"\nüîç Recherche classique: '{query}'")
        
        # Recherche g√©n√©rale
        results = search.search_legal_knowledge(query, top_k=3)
        print(f"  R√©sultats g√©n√©raux: {len(results)}")
        
        # Recherche d√©ontologie
        deont_results = search.search_deontologie(query, top_k=2)
        print(f"  R√©sultats d√©ontologie: {len(deont_results)}")
        
        if deont_results:
            for i, result in enumerate(deont_results[:2]):
                print(f"    {i+1}. {result['article']} (score: {result['relevance_score']:.2f})")
                print(f"       {result['content'][:80]}...")

if __name__ == "__main__":
    test_chromadb_search() 