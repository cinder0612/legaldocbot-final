#!/usr/bin/env python3
"""
Module de traitement de nouveaux documents pour LegalDocBot
Permet d'ajouter de nouveaux PDFs √† la base de connaissances ChromaDB
"""

import os
import sys
import logging
from pathlib import Path
from typing import List, Optional
import chromadb
from chromadb.config import Settings
import PyPDF2
import fitz  # PyMuPDF

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DocumentProcessor:
    """Processeur de documents pour ajouter de nouveaux PDFs √† ChromaDB"""
    
    def __init__(self, chroma_db_path: str = "chroma_db"):
        self.chroma_db_path = Path(chroma_db_path)
        self.knowledge_base_path = Path("knowledge base")
        
        # Cr√©er les dossiers si n√©cessaire
        self.knowledge_base_path.mkdir(exist_ok=True)
        
        # Initialiser ChromaDB
        self.client = chromadb.PersistentClient(
            path=str(self.chroma_db_path),
            settings=Settings(anonymized_telemetry=False)
        )
        
        # Collection pour les documents
        self.collection = self.client.get_or_create_collection(
            name="legal_documents",
            metadata={"description": "Base de connaissances juridique"}
        )
    
    def extract_text_from_pdf(self, pdf_path: Path) -> str:
        """Extrait le texte d'un fichier PDF"""
        try:
            # Essayer PyMuPDF d'abord (plus robuste)
            doc = fitz.open(str(pdf_path))
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return text.strip()
            
        except ImportError:
            # Fallback vers PyPDF2
            try:
                with open(pdf_path, 'rb') as file:
                    reader = PyPDF2.PdfReader(file)
                    text = ""
                    for page in reader.pages:
                        text += page.extract_text()
                    return text.strip()
            except Exception as e:
                logger.error(f"Erreur extraction PDF {pdf_path}: {e}")
                return ""
    
    def process_single_document(self, pdf_path: Path) -> bool:
        """Traite un seul document PDF"""
        try:
            logger.info(f"üìÑ Traitement de {pdf_path.name}...")
            
            # Extraire le texte
            text = self.extract_text_from_pdf(pdf_path)
            if not text:
                logger.warning(f"‚ö†Ô∏è Aucun texte extrait de {pdf_path.name}")
                return False
            
            # D√©couper en chunks
            chunks = self._split_text_into_chunks(text, chunk_size=1000, overlap=200)
            
            # Ajouter √† ChromaDB
            documents = []
            metadatas = []
            ids = []
            
            for i, chunk in enumerate(chunks):
                doc_id = f"{pdf_path.stem}_{i}"
                documents.append(chunk)
                metadatas.append({
                    "source": pdf_path.name,
                    "chunk_index": i,
                    "total_chunks": len(chunks),
                    "file_path": str(pdf_path)
                })
                ids.append(doc_id)
            
            # Ins√©rer dans ChromaDB
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"‚úÖ {pdf_path.name} trait√©: {len(chunks)} chunks ajout√©s")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement {pdf_path.name}: {e}")
            return False
    
    def _split_text_into_chunks(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """D√©coupe le texte en chunks avec overlap"""
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # Ajuster la fin pour ne pas couper au milieu d'un mot
            if end < len(text):
                # Chercher le dernier espace dans la fen√™tre
                last_space = text.rfind(' ', start, end)
                if last_space > start:
                    end = last_space
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # Avancer avec overlap
            start = end - overlap
            if start >= len(text):
                break
        
        return chunks
    
    def process_knowledge_base(self) -> dict:
        """Traite tous les PDFs dans le dossier knowledge base"""
        logger.info("üìö Traitement de la base de connaissances...")
        
        if not self.knowledge_base_path.exists():
            logger.warning("‚ö†Ô∏è Dossier 'knowledge base' non trouv√©")
            return {"success": 0, "failed": 0, "total": 0}
        
        # Trouver tous les PDFs
        pdf_files = list(self.knowledge_base_path.glob("*.pdf"))
        
        if not pdf_files:
            logger.info("‚ÑπÔ∏è Aucun fichier PDF trouv√© dans 'knowledge base'")
            return {"success": 0, "failed": 0, "total": 0}
        
        logger.info(f"üìÑ {len(pdf_files)} fichiers PDF trouv√©s")
        
        success_count = 0
        failed_count = 0
        
        for pdf_file in pdf_files:
            if self.process_single_document(pdf_file):
                success_count += 1
            else:
                failed_count += 1
        
        # Statistiques
        stats = {
            "success": success_count,
            "failed": failed_count,
            "total": len(pdf_files)
        }
        
        logger.info(f"üìä R√©sultats: {success_count} succ√®s, {failed_count} √©checs sur {len(pdf_files)} fichiers")
        
        return stats
    
    def add_new_document(self, pdf_path: str) -> bool:
        """Ajoute un nouveau document PDF"""
        pdf_path = Path(pdf_path)
        
        if not pdf_path.exists():
            logger.error(f"‚ùå Fichier non trouv√©: {pdf_path}")
            return False
        
        if pdf_path.suffix.lower() != '.pdf':
            logger.error(f"‚ùå Fichier non PDF: {pdf_path}")
            return False
        
        # Copier dans knowledge base
        dest_path = self.knowledge_base_path / pdf_path.name
        try:
            import shutil
            shutil.copy2(pdf_path, dest_path)
            logger.info(f"üìã {pdf_path.name} copi√© dans knowledge base")
        except Exception as e:
            logger.error(f"‚ùå Erreur copie: {e}")
            return False
        
        # Traiter le document
        return self.process_single_document(dest_path)
    
    def get_collection_stats(self) -> dict:
        """Retourne les statistiques de la collection ChromaDB"""
        try:
            count = self.collection.count()
            return {
                "total_documents": count,
                "collection_name": self.collection.name,
                "chroma_db_path": str(self.chroma_db_path)
            }
        except Exception as e:
            logger.error(f"‚ùå Erreur statistiques: {e}")
            return {}

# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

def get_document_processor() -> DocumentProcessor:
    """Retourne une instance du processeur de documents"""
    return DocumentProcessor()

def process_new_documents() -> dict:
    """Traite tous les nouveaux documents dans knowledge base"""
    processor = get_document_processor()
    return processor.process_knowledge_base()

def add_document(pdf_path: str) -> bool:
    """Ajoute un nouveau document PDF"""
    processor = get_document_processor()
    return processor.add_new_document(pdf_path)

def get_database_stats() -> dict:
    """Retourne les statistiques de la base de donn√©es"""
    processor = get_document_processor()
    return processor.get_collection_stats()

# ============================================================================
# TEST
# ============================================================================

if __name__ == "__main__":
    print("üß™ TEST PROCESSEUR DE DOCUMENTS")
    print("=" * 50)
    
    processor = DocumentProcessor()
    
    # Statistiques actuelles
    stats = processor.get_collection_stats()
    print(f"\nüìä Statistiques ChromaDB:")
    print(f"  Documents: {stats.get('total_documents', 0)}")
    print(f"  Collection: {stats.get('collection_name', 'N/A')}")
    
    # Traiter les nouveaux documents
    print(f"\nüìö Traitement des nouveaux documents...")
    results = processor.process_knowledge_base()
    
    print(f"\nüìà R√©sultats:")
    print(f"  Succ√®s: {results['success']}")
    print(f"  √âchecs: {results['failed']}")
    print(f"  Total: {results['total']}")
    
    # Nouvelles statistiques
    new_stats = processor.get_collection_stats()
    print(f"\nüìä Nouvelles statistiques:")
    print(f"  Documents: {new_stats.get('total_documents', 0)}")
    
    if results['success'] > 0:
        print(f"‚úÖ {results['success']} documents ajout√©s avec succ√®s")
    else:
        print(f"‚ÑπÔ∏è Aucun nouveau document trait√©") 